{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np                                                 #used for processing arrayobjects and computations on them\n",
    "import matplotlib.pyplot as plt                                    #used for data visualization\n",
    "import matplotlib.image as mpimg                                   #image loading and rescaling\n",
    "import pandas as pd                                                #data analysis and manipulation\n",
    "\n",
    "import seaborn as sns                                              #high level data visualization\n",
    "                                                                    #Plot pairwise relationships in a dataset.\n",
    "                                                                   # It is used to visualize the the distribution of the dataset\n",
    "\n",
    "from sklearn.metrics import confusion_matrix                       #to check the accuracy of the model developed\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('forest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>b1</th>\n",
       "      <th>b2</th>\n",
       "      <th>b3</th>\n",
       "      <th>b4</th>\n",
       "      <th>b5</th>\n",
       "      <th>b6</th>\n",
       "      <th>b7</th>\n",
       "      <th>b8</th>\n",
       "      <th>b9</th>\n",
       "      <th>pred_minus_obs_H_b1</th>\n",
       "      <th>...</th>\n",
       "      <th>pred_minus_obs_S_b1</th>\n",
       "      <th>pred_minus_obs_S_b2</th>\n",
       "      <th>pred_minus_obs_S_b3</th>\n",
       "      <th>pred_minus_obs_S_b4</th>\n",
       "      <th>pred_minus_obs_S_b5</th>\n",
       "      <th>pred_minus_obs_S_b6</th>\n",
       "      <th>pred_minus_obs_S_b7</th>\n",
       "      <th>pred_minus_obs_S_b8</th>\n",
       "      <th>pred_minus_obs_S_b9</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>67</td>\n",
       "      <td>51</td>\n",
       "      <td>68</td>\n",
       "      <td>115</td>\n",
       "      <td>69</td>\n",
       "      <td>111</td>\n",
       "      <td>136</td>\n",
       "      <td>31</td>\n",
       "      <td>67</td>\n",
       "      <td>47.70</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.27</td>\n",
       "      <td>-1.80</td>\n",
       "      <td>-6.32</td>\n",
       "      <td>-20.88</td>\n",
       "      <td>-1.63</td>\n",
       "      <td>-6.13</td>\n",
       "      <td>-22.56</td>\n",
       "      <td>-5.53</td>\n",
       "      <td>-8.11</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>28</td>\n",
       "      <td>51</td>\n",
       "      <td>99</td>\n",
       "      <td>50</td>\n",
       "      <td>97</td>\n",
       "      <td>82</td>\n",
       "      <td>26</td>\n",
       "      <td>59</td>\n",
       "      <td>47.93</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.13</td>\n",
       "      <td>-2.11</td>\n",
       "      <td>-6.35</td>\n",
       "      <td>-21.94</td>\n",
       "      <td>-1.22</td>\n",
       "      <td>-6.13</td>\n",
       "      <td>-22.20</td>\n",
       "      <td>-3.41</td>\n",
       "      <td>-6.57</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63</td>\n",
       "      <td>26</td>\n",
       "      <td>50</td>\n",
       "      <td>95</td>\n",
       "      <td>49</td>\n",
       "      <td>91</td>\n",
       "      <td>81</td>\n",
       "      <td>26</td>\n",
       "      <td>57</td>\n",
       "      <td>53.09</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.64</td>\n",
       "      <td>-1.81</td>\n",
       "      <td>-4.70</td>\n",
       "      <td>-19.39</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>-5.01</td>\n",
       "      <td>-20.89</td>\n",
       "      <td>-3.96</td>\n",
       "      <td>-6.85</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>63</td>\n",
       "      <td>42</td>\n",
       "      <td>63</td>\n",
       "      <td>97</td>\n",
       "      <td>66</td>\n",
       "      <td>108</td>\n",
       "      <td>111</td>\n",
       "      <td>28</td>\n",
       "      <td>59</td>\n",
       "      <td>52.41</td>\n",
       "      <td>...</td>\n",
       "      <td>-20.20</td>\n",
       "      <td>-1.89</td>\n",
       "      <td>-5.47</td>\n",
       "      <td>-21.65</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>-5.71</td>\n",
       "      <td>-22.19</td>\n",
       "      <td>-3.41</td>\n",
       "      <td>-6.52</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>27</td>\n",
       "      <td>50</td>\n",
       "      <td>83</td>\n",
       "      <td>51</td>\n",
       "      <td>90</td>\n",
       "      <td>76</td>\n",
       "      <td>26</td>\n",
       "      <td>56</td>\n",
       "      <td>68.54</td>\n",
       "      <td>...</td>\n",
       "      <td>-18.62</td>\n",
       "      <td>-2.17</td>\n",
       "      <td>-7.11</td>\n",
       "      <td>-21.12</td>\n",
       "      <td>-1.56</td>\n",
       "      <td>-6.35</td>\n",
       "      <td>-22.19</td>\n",
       "      <td>-4.45</td>\n",
       "      <td>-7.32</td>\n",
       "      <td>s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   b1  b2  b3   b4  b5   b6   b7  b8  b9  pred_minus_obs_H_b1  ...    \\\n",
       "0  67  51  68  115  69  111  136  31  67                47.70  ...     \n",
       "1  67  28  51   99  50   97   82  26  59                47.93  ...     \n",
       "2  63  26  50   95  49   91   81  26  57                53.09  ...     \n",
       "3  63  42  63   97  66  108  111  28  59                52.41  ...     \n",
       "4  46  27  50   83  51   90   76  26  56                68.54  ...     \n",
       "\n",
       "   pred_minus_obs_S_b1  pred_minus_obs_S_b2  pred_minus_obs_S_b3  \\\n",
       "0               -18.27                -1.80                -6.32   \n",
       "1               -20.13                -2.11                -6.35   \n",
       "2               -17.64                -1.81                -4.70   \n",
       "3               -20.20                -1.89                -5.47   \n",
       "4               -18.62                -2.17                -7.11   \n",
       "\n",
       "   pred_minus_obs_S_b4  pred_minus_obs_S_b5  pred_minus_obs_S_b6  \\\n",
       "0               -20.88                -1.63                -6.13   \n",
       "1               -21.94                -1.22                -6.13   \n",
       "2               -19.39                -0.65                -5.01   \n",
       "3               -21.65                -0.99                -5.71   \n",
       "4               -21.12                -1.56                -6.35   \n",
       "\n",
       "   pred_minus_obs_S_b7  pred_minus_obs_S_b8  pred_minus_obs_S_b9  class  \n",
       "0               -22.56                -5.53                -8.11     d   \n",
       "1               -22.20                -3.41                -6.57     s   \n",
       "2               -20.89                -3.96                -6.85     s   \n",
       "3               -22.19                -3.41                -6.52     d   \n",
       "4               -22.19                -4.45                -7.32     s   \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#looking at the first 5 values of the dataset\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     b1  b2  b3  b4  b5  b6  b7  b8  b9  pred_minus_obs_H_b1  ...    \\\n",
      "0    35  27  21  43  25  27  72  12  20                   72  ...     \n",
      "1    35   5   4  27   6  13  32   7  12                   75  ...     \n",
      "2    31   3   3  23   5   7  31   7  10                  112  ...     \n",
      "3    31  19  16  25  22  24  60   9  12                  104  ...     \n",
      "4    14   4   3  11   7   6  26   7   9                  250  ...     \n",
      "5    27  34  34  21  26  20  42  10  11                  129  ...     \n",
      "6    51   5   7  45   7  12  55   8  17                   27  ...     \n",
      "7    31  14  11  23  14  17  39   8  15                  111  ...     \n",
      "8    45   6   5  31   7   9  37   8  12                   29  ...     \n",
      "9    24   9   7  27   6  11  31   5  10                  149  ...     \n",
      "10   38  29  25  32  29  28  54  11  17                   50  ...     \n",
      "11   27   6   6  26   8  10  35   8  13                  123  ...     \n",
      "12   10   6   3  11  10   9  20   6   7                  267  ...     \n",
      "13   46   7   8  40   9  15  54   8  15                   26  ...     \n",
      "14   18   2   1  24   4   8  13   4   5                  236  ...     \n",
      "15   26  45  52  10  30  24   4  13  11                  141  ...     \n",
      "16   44  44  39  46  30  33  64  13  22                   25  ...     \n",
      "17   46   4   7  45   5  11  55   8  14                   34  ...     \n",
      "18   46   5   6  38   4   8  35   5  11                   22  ...     \n",
      "19   24  20  16  24  19  17  61   8  12                  162  ...     \n",
      "20   20   5   6  28   4   4   9   4   3                  191  ...     \n",
      "21   47   4   7  43   5  11  45   6  12                   17  ...     \n",
      "22   29  39  38  15  38  38  56  33  41                   94  ...     \n",
      "23   35   9   9  30  11  15  46   9  15                   60  ...     \n",
      "24   38   5   4  32   7  11  38   7  13                   52  ...     \n",
      "25   31   6   6  27   6  10  35   7  13                   95  ...     \n",
      "26   18  19  15  18   8  11  21   6   8                  233  ...     \n",
      "27   20   5   6  20  16  19  32   8  10                  218  ...     \n",
      "28   27   7   5  18  10   9  30   7  11                  140  ...     \n",
      "29   39   4   6  37   5  12  45   7  12                   47  ...     \n",
      "..   ..  ..  ..  ..  ..  ..  ..  ..  ..                  ...  ...     \n",
      "266  13   4   3  11   4   0  20   5   6                  219  ...     \n",
      "267  44   5   6  43   8  13  49   5  12                   48  ...     \n",
      "268  40   5   7  35   6   7  42   5   8                   38  ...     \n",
      "269  16  10  10  21  10  11  44   6   7                  232  ...     \n",
      "270  15   3   1  14   1   2  25   5   5                  182  ...     \n",
      "271  39  52  55  18  34  26  30  17  19                   44  ...     \n",
      "272  25   7   5  24   6   8  48   5  11                  199  ...     \n",
      "273  39   5   5  36  14  17  40   7  11                   73  ...     \n",
      "274  52   7  10  43   4   9  55   6  14                    2  ...     \n",
      "275  16   8   5  21   6   8  51   6  11                  256  ...     \n",
      "276  22   3   3  28  11  15  22   4   7                  227  ...     \n",
      "277  31   6   4  20   2   2  22   4   6                   83  ...     \n",
      "278  38   5   6  31   9  15  44   5  14                   67  ...     \n",
      "279  25   7   6  17   4   3  40   5   8                  101  ...     \n",
      "280  48   8   7  46   6   8  56   5  12                   12  ...     \n",
      "281  27   9   9  18   6   6  35   6   9                   93  ...     \n",
      "282  44   5   6  43  11  15  52   5  11                   43  ...     \n",
      "283  17   2   3  20  10  16  10   4   5                  258  ...     \n",
      "284  19  18  14  29  21  24  60   7  13                  248  ...     \n",
      "285  23  31  25  19  34  29  36  15  21                  202  ...     \n",
      "286  37  25  29  19   8   7  42   6  10                   20  ...     \n",
      "287  17   3   1  35  15  20  12   3   6                  260  ...     \n",
      "288  23   3   5  20  11  14  15   4   9                  213  ...     \n",
      "289  39   5   4  24   2   4  42   6  11                   18  ...     \n",
      "290   7  13  10  19  15  17  43   8  13                  280  ...     \n",
      "291  52   7  10  40   7  14  42   7  15                    7  ...     \n",
      "292  21   2   2  27   7   9  34   7  11                  211  ...     \n",
      "293  27   3   2  31   3   8  32   6   9                  128  ...     \n",
      "294  25  25  19  31  20  22  62   9  12                  171  ...     \n",
      "295  53   5   9  48   8  14  51   8  18                   21  ...     \n",
      "\n",
      "     pred_minus_obs_S_b1  pred_minus_obs_S_b2  pred_minus_obs_S_b3  \\\n",
      "0                    185                   48                   31   \n",
      "1                    116                   32                   29   \n",
      "2                    201                   47                   94   \n",
      "3                    114                   40                   61   \n",
      "4                    174                   30                   14   \n",
      "5                    215                   37                   26   \n",
      "6                      2                   42                   47   \n",
      "7                     86                   53                   84   \n",
      "8                    219                   26                   19   \n",
      "9                    157                   72                   72   \n",
      "10                   138                   13                    4   \n",
      "11                   160                   83                   85   \n",
      "12                   107                   17                    5   \n",
      "13                    89                   21                   22   \n",
      "14                    60                   43                   59   \n",
      "15                   104                   50                   93   \n",
      "16                   237                  128                  203   \n",
      "17                    62                   52                   62   \n",
      "18                   119                   20                   15   \n",
      "19                   108                   59                   92   \n",
      "20                   132                   22                   11   \n",
      "21                   124                   25                   16   \n",
      "22                   183                  147                  180   \n",
      "23                   236                  140                  212   \n",
      "24                   189                  143                  172   \n",
      "25                   130                   73                  114   \n",
      "26                    90                   23                   76   \n",
      "27                    79                   36                   39   \n",
      "28                    89                   43                   54   \n",
      "29                   159                  118                  126   \n",
      "..                   ...                  ...                  ...   \n",
      "266                  227                  119                   56   \n",
      "267                    8                  167                  177   \n",
      "268                  101                   77                   99   \n",
      "269                   72                   56                   71   \n",
      "270                  222                  117                   81   \n",
      "271                   92                   61                   49   \n",
      "272                    0                  108                   52   \n",
      "273                   25                  198                  214   \n",
      "274                  249                  140                  108   \n",
      "275                    4                   78                   48   \n",
      "276                   42                  200                  186   \n",
      "277                   88                   65                   50   \n",
      "278                   40                  139                  119   \n",
      "279                  203                   80                   91   \n",
      "280                  171                    9                   54   \n",
      "281                  172                   66                   73   \n",
      "282                   32                  179                  193   \n",
      "283                   27                  202                  226   \n",
      "284                   27                  200                  215   \n",
      "285                   43                  160                  148   \n",
      "286                  254                  141                  137   \n",
      "287                   34                  201                  219   \n",
      "288                   28                  199                  224   \n",
      "289                  246                  138                  133   \n",
      "290                  181                   41                   27   \n",
      "291                  228                   38                   35   \n",
      "292                  233                   49                   96   \n",
      "293                  247                   16                   30   \n",
      "294                   72                   59                   98   \n",
      "295                    1                   40                   46   \n",
      "\n",
      "     pred_minus_obs_S_b4  pred_minus_obs_S_b5  pred_minus_obs_S_b6  \\\n",
      "0                    132                    8                   13   \n",
      "1                    105                   31                   13   \n",
      "2                    180                   85                   64   \n",
      "3                    109                   52                   24   \n",
      "4                    126                   11                    6   \n",
      "5                    133                    4                    9   \n",
      "6                      1                    3                    1   \n",
      "7                     98                   57                   31   \n",
      "8                    151                    5                    8   \n",
      "9                     55                   37                   45   \n",
      "10                   191                   18                   10   \n",
      "11                    61                   42                   55   \n",
      "12                   113                   31                   10   \n",
      "13                    80                   37                   14   \n",
      "14                    12                   31                    5   \n",
      "15                    44                   50                   47   \n",
      "16                   236                   95                  142   \n",
      "17                    23                   40                   12   \n",
      "18                   172                   36                   38   \n",
      "19                    39                   52                   54   \n",
      "20                   174                   40                   28   \n",
      "21                   171                   41                   30   \n",
      "22                   184                   68                  107   \n",
      "23                   250                  106                  171   \n",
      "24                   137                   75                  110   \n",
      "25                    46                   55                   74   \n",
      "26                    62                   52                   44   \n",
      "27                     7                   22                    4   \n",
      "28                    13                   37                   23   \n",
      "29                   103                   63                   92   \n",
      "..                   ...                  ...                  ...   \n",
      "266                  242                   58                   48   \n",
      "267                   26                   63                   90   \n",
      "268                   58                   39                   42   \n",
      "269                   29                   31                   37   \n",
      "270                  239                   56                   94   \n",
      "271                  213                   34                   31   \n",
      "272                    3                   33                   21   \n",
      "273                   66                   47                  106   \n",
      "274                  247                   69                   91   \n",
      "275                    4                   20                   20   \n",
      "276                   19                    6                   53   \n",
      "277                  194                   35                   47   \n",
      "278                    9                   38                   69   \n",
      "279                  237                   58                  100   \n",
      "280                   84                   19                   41   \n",
      "281                  152                   38                   66   \n",
      "282                   30                   53                   93   \n",
      "283                    2                    5                   10   \n",
      "284                   14                   16                   65   \n",
      "285                   15                   47                   83   \n",
      "286                  238                   72                  117   \n",
      "287                   20                   19                   78   \n",
      "288                   40                   32                   85   \n",
      "289                  249                   79                  131   \n",
      "290                  128                   10                   11   \n",
      "291                  197                    1                   11   \n",
      "292                  227                  100                   86   \n",
      "293                  102                    0                    3   \n",
      "294                   67                   65                   36   \n",
      "295                    0                    2                    0   \n",
      "\n",
      "     pred_minus_obs_S_b7  pred_minus_obs_S_b8  pred_minus_obs_S_b9  class  \n",
      "0                     42                    4                    4      0  \n",
      "1                     52                    9                    9      3  \n",
      "2                     78                    8                    8      3  \n",
      "3                     53                    9                   10      0  \n",
      "4                     53                    6                    6      3  \n",
      "5                     15                    2                    2      0  \n",
      "6                      1                   70                   47      1  \n",
      "7                     46                   11                   11      2  \n",
      "8                     34                    3                    3      3  \n",
      "9                    116                   97                  109      3  \n",
      "10                    95                   12                   14      2  \n",
      "11                   126                  105                  118      3  \n",
      "12                    70                   21                   13      0  \n",
      "13                    58                   14                   12      1  \n",
      "14                    14                   50                   30      3  \n",
      "15                    85                   59                   45      2  \n",
      "16                   252                  179                  187      0  \n",
      "17                    20                   39                   25      1  \n",
      "18                   123                   23                   24      1  \n",
      "19                    84                   63                   56      0  \n",
      "20                   109                   25                   17      3  \n",
      "21                   107                   27                   19      1  \n",
      "22                   215                  175                  159      2  \n",
      "23                   255                  183                  199      3  \n",
      "24                   199                  157                  166      3  \n",
      "25                   111                   73                   79      3  \n",
      "26                    57                   18                   15      3  \n",
      "27                    21                   49                   33      3  \n",
      "28                    59                   49                   44      3  \n",
      "29                   154                  126                  135      3  \n",
      "..                   ...                  ...                  ...    ...  \n",
      "266                  228                   68                   91      3  \n",
      "267                   25                  123                  127      1  \n",
      "268                  124                  150                  152      1  \n",
      "269                   90                  142                  146      0  \n",
      "270                  239                  108                  134      3  \n",
      "271                  139                   95                   90      0  \n",
      "272                    4                  134                  114      3  \n",
      "273                   11                   74                   78      1  \n",
      "274                  253                   77                  116      1  \n",
      "275                   10                  123                  120      2  \n",
      "276                    6                   15                   23      3  \n",
      "277                  143                  113                  120      3  \n",
      "278                   32                   99                  106      1  \n",
      "279                  231                  114                  136      3  \n",
      "280                  174                   99                  133      1  \n",
      "281                  197                  117                  131      3  \n",
      "282                   40                  103                  112      1  \n",
      "283                    2                   23                   42      3  \n",
      "284                    5                   29                   41      2  \n",
      "285                   38                  101                  109      2  \n",
      "286                  260                  102                  145      0  \n",
      "287                    7                   39                   51      3  \n",
      "288                    8                   57                   66      3  \n",
      "289                  256                  110                  141      1  \n",
      "290                   43                    5                    5      1  \n",
      "291                   17                    0                    0      3  \n",
      "292                   94                    7                    7      3  \n",
      "293                    3                    1                    1      0  \n",
      "294                   39                   25                   16      1  \n",
      "295                    0                   73                   52      3  \n",
      "\n",
      "[296 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "Enc = LabelEncoder()\n",
    "data_tf = dataset.copy()\n",
    "for i in dataset.columns:\n",
    "   data_tf[i]=Enc.fit_transform(dataset[i])\n",
    "    \n",
    "print(data_tf)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "data_tf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting the dataset in independent and dependent variables\n",
    "\n",
    "X = data_tf.drop(['class'], axis=1)                                  # all rows first and first 4 columns\n",
    "y = data_tf['class'].values  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 82)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**HYPERPARAMETER TUNNING USING GRID SEARCH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................................... C=1, gamma=1, total=   0.1s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................................... C=1, gamma=1, total=   0.0s\n",
      "[CV] C=1, gamma=1 ....................................................\n",
      "[CV] ..................................... C=1, gamma=1, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................................... C=1, gamma=0.1, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................................... C=1, gamma=0.1, total=   0.0s\n",
      "[CV] C=1, gamma=0.1 ..................................................\n",
      "[CV] ................................... C=1, gamma=0.1, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................................. C=1, gamma=0.01, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................................. C=1, gamma=0.01, total=   0.0s\n",
      "[CV] C=1, gamma=0.01 .................................................\n",
      "[CV] .................................. C=1, gamma=0.01, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ................................. C=1, gamma=0.001, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................................. C=1, gamma=0.001, total=   0.0s\n",
      "[CV] C=1, gamma=0.001 ................................................\n",
      "[CV] ................................. C=1, gamma=0.001, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................................ C=1, gamma=0.0001, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................................ C=1, gamma=0.0001, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001 ...............................................\n",
      "[CV] ................................ C=1, gamma=0.0001, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................................... C=10, gamma=1, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................................... C=10, gamma=1, total=   0.0s\n",
      "[CV] C=10, gamma=1 ...................................................\n",
      "[CV] .................................... C=10, gamma=1, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................................. C=10, gamma=0.1, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................................. C=10, gamma=0.1, total=   0.0s\n",
      "[CV] C=10, gamma=0.1 .................................................\n",
      "[CV] .................................. C=10, gamma=0.1, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................................. C=10, gamma=0.01, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................................. C=10, gamma=0.01, total=   0.0s\n",
      "[CV] C=10, gamma=0.01 ................................................\n",
      "[CV] ................................. C=10, gamma=0.01, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................................ C=10, gamma=0.001, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................................ C=10, gamma=0.001, total=   0.0s\n",
      "[CV] C=10, gamma=0.001 ...............................................\n",
      "[CV] ................................ C=10, gamma=0.001, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] ............................... C=10, gamma=0.0001, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] ............................... C=10, gamma=0.0001, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001 ..............................................\n",
      "[CV] ............................... C=10, gamma=0.0001, total=   0.0s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ................................... C=100, gamma=1, total=   0.0s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ................................... C=100, gamma=1, total=   0.0s\n",
      "[CV] C=100, gamma=1 ..................................................\n",
      "[CV] ................................... C=100, gamma=1, total=   0.0s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ................................. C=100, gamma=0.1, total=   0.0s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ................................. C=100, gamma=0.1, total=   0.0s\n",
      "[CV] C=100, gamma=0.1 ................................................\n",
      "[CV] ................................. C=100, gamma=0.1, total=   0.0s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ................................ C=100, gamma=0.01, total=   0.0s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ................................ C=100, gamma=0.01, total=   0.0s\n",
      "[CV] C=100, gamma=0.01 ...............................................\n",
      "[CV] ................................ C=100, gamma=0.01, total=   0.0s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ............................... C=100, gamma=0.001, total=   0.0s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ............................... C=100, gamma=0.001, total=   0.0s\n",
      "[CV] C=100, gamma=0.001 ..............................................\n",
      "[CV] ............................... C=100, gamma=0.001, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001 .............................................\n",
      "[CV] .............................. C=100, gamma=0.0001, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001 .............................................\n",
      "[CV] .............................. C=100, gamma=0.0001, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001 .............................................\n",
      "[CV] .............................. C=100, gamma=0.0001, total=   0.0s\n",
      "[CV] C=1000, gamma=1 .................................................\n",
      "[CV] .................................. C=1000, gamma=1, total=   0.0s\n",
      "[CV] C=1000, gamma=1 .................................................\n",
      "[CV] .................................. C=1000, gamma=1, total=   0.0s\n",
      "[CV] C=1000, gamma=1 .................................................\n",
      "[CV] .................................. C=1000, gamma=1, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1 ...............................................\n",
      "[CV] ................................ C=1000, gamma=0.1, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1 ...............................................\n",
      "[CV] ................................ C=1000, gamma=0.1, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1 ...............................................\n",
      "[CV] ................................ C=1000, gamma=0.1, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01 ..............................................\n",
      "[CV] ............................... C=1000, gamma=0.01, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01 ..............................................\n",
      "[CV] ............................... C=1000, gamma=0.01, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01 ..............................................\n",
      "[CV] ............................... C=1000, gamma=0.01, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] .............................. C=1000, gamma=0.001, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] .............................. C=1000, gamma=0.001, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001 .............................................\n",
      "[CV] .............................. C=1000, gamma=0.001, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001 ............................................\n",
      "[CV] ............................. C=1000, gamma=0.0001, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001 ............................................\n",
      "[CV] ............................. C=1000, gamma=0.0001, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001 ............................................\n",
      "[CV] ............................. C=1000, gamma=0.0001, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  60 out of  60 | elapsed:    1.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'C': [1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "param_grid = {'C': [1, 10, 100, 1000], 'gamma': [1, 0.1, 0.01, 0.001, 0.0001]}\n",
    "# dictionary for values of parameters C and gamma.\n",
    "grid = GridSearchCV(SVC(), param_grid, verbose=2)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.0001}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 1 3 3 2 3 0 3 3 3 0 0 0 3 0 3 3 1 0 3 3 3 3 3 0 3 3 0 3 3 3 0 0 3 3 3\n",
      " 3 3 3 3 3 3 0 0 3 3 3 0 0 3 3 0 3 3 0 0 3 3 0]\n"
     ]
    }
   ],
   "source": [
    "print(grid_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODEL EVELUATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0  0  3]\n",
      " [ 1  3  0  5]\n",
      " [ 2  0  1  6]\n",
      " [ 3  0  0 24]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.80      0.73        15\n",
      "           1       1.00      0.33      0.50         9\n",
      "           2       1.00      0.11      0.20         9\n",
      "           3       0.63      0.89      0.74        27\n",
      "\n",
      "    accuracy                           0.67        60\n",
      "   macro avg       0.82      0.53      0.54        60\n",
      "weighted avg       0.75      0.67      0.62        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Splitting the dataset into the Training set and Test set\n",
    "#   x_train is the       :---> training data set.\n",
    "#  y_train is the        :---> set of labels to all the data in x_train.\n",
    "#your model after the model has gone through initial vetting by the validation set.\n",
    "#x_test is the test data set.\n",
    "#y_test is the set of labels to all the data in x_test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "\n",
    "# Feature Scaling to bring the variable in a single scale\n",
    "# scaling happen independently on each feature by computing the relevant statistics on the samples in the training set\n",
    "\n",
    "\n",
    "\n",
    "X_train = sc.fit_transform(X_train)   #Fit to data, then transform it.\n",
    "X_test = sc.transform(X_test)         #Perform standardization(rescaling original data without changing the nature)\n",
    "                                        #by centering and scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Linear Kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "    kernel='linear', max_iter=-1, probability=False, random_state=0,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting SVC Classification to the Training set with linear kernel\n",
    "# Kernal Function : xi * xj\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svcclassifier1 = SVC(kernel = 'linear', random_state = 0)\n",
    "svcclassifier1.fit(X_train, y_train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 1 3 3 2 1 0 0 3 3 0 0 0 0 0 0 3 1 0 2 2 3 3 3 0 2 3 0 3 3 0 0 0 3 3 3\n",
      " 3 3 3 3 1 3 0 0 3 3 3 0 0 2 3 0 1 3 3 0 3 3 0]\n"
     ]
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "\n",
    "\n",
    "\n",
    "x_pred1 = svcclassifier1.predict(X_train)\n",
    "y_pred1 = svcclassifier1.predict(X_test)\n",
    "print(y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 3],\n",
       "       [3, 3]])"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets see the actual and predicted value side by side\n",
    "\n",
    "y_compare1 = np.vstack((y_test,y_pred1)).T\n",
    "\n",
    "\n",
    "#actual value on the left side and predicted value on the right hand side\n",
    "#printing the top 5 values\n",
    "\n",
    "y_compare1[:5,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********FOR LINEAR KERNAL*********\n",
      "\n",
      " Testing Accuracy of SVM using Linear Kernel : 80.0%\n",
      " Training Accuracy of SVM using Linear Kernal : 92.37288135593221%\n",
      "1) Confusion Matrix:  \n",
      "[[14  0  0  1]\n",
      " [ 0  6  0  3]\n",
      " [ 3  0  5  1]\n",
      " [ 4  0  0 23]]\n",
      "\n",
      "2) Shape of Confusion Matrix\n",
      "(4, 4)\n",
      "\n",
      "3) Correct predictions:   48\n",
      "\n",
      "4)False predictions:  12\n",
      "\n",
      "5)Precision Score:  0.8363\n",
      "\n",
      "6)Recall Score: 0.8000\n",
      "\n",
      "7)F1 Score: 0.7980\n",
      "\n",
      "8)Accuracy of the SVC Clasification (USING LINEAR KERNAL)is:  80.0%"
     ]
    }
   ],
   "source": [
    "# Making the Confusion Matrix\n",
    "print('*********FOR LINEAR KERNAL*********')\n",
    "\n",
    "ac1=accuracy_score(y_test, y_pred1)\n",
    "print('\\n Testing Accuracy of SVM using Linear Kernel :',ac1*100,end='%')\n",
    "\n",
    "tac1 = accuracy_score(y_train, x_pred1)\n",
    "print('\\n Training Accuracy of SVM using Linear Kernal :',tac1*100,end='%')\n",
    "\n",
    "\n",
    "\n",
    "print('\\n1) Confusion Matrix:  ')\n",
    "\n",
    "cm1 = confusion_matrix(y_test, y_pred1)\n",
    "print(cm1)\n",
    "\n",
    "print('\\n2) Shape of Confusion Matrix')\n",
    "a1 = cm1.shape\n",
    "print(a1)\n",
    "\n",
    "\n",
    "corrPred1 = 0\n",
    "falsePred1 = 0\n",
    "\n",
    "for row1 in range(a1[0]):\n",
    "    for c1 in range(a1[1]):\n",
    "        if row1 == c1:\n",
    "            corrPred1 +=cm1[row1,c1]\n",
    "        else:\n",
    "            falsePred1 += cm1[row1,c1]\n",
    "     \n",
    "  \n",
    "print('\\n3) Correct predictions:  ', corrPred1)\n",
    "print('\\n4)False predictions: ', falsePred1)\n",
    "kernelLinearAccuracy = corrPred1/(cm1.sum())\n",
    "\n",
    "\n",
    "print(\"\\n5)Precision Score:  {0:.4f}\".format(precision_score(y_test, y_pred1,average='weighted'))) \n",
    "                                                           \n",
    "print(\"\\n6)Recall Score: {0:.4f}\".format(recall_score(y_test, y_pred1, average='weighted'))) \n",
    "                                                    \n",
    "                                                    \n",
    "print(\"\\n7)F1 Score: {0:.4f}\".format(f1_score(y_test,y_pred1,  average='weighted'))) \n",
    "                                           \n",
    "\n",
    "print ('\\n8)Accuracy of the SVC Clasification (USING LINEAR KERNAL)is: ', kernelLinearAccuracy*100,end='%')        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using polynomial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 1 3 3 2 3 0 0 3 3 3 0 0 0 0 3 3 1 0 0 2 3 3 3 0 0 3 3 3 3 0 0 3 3 3 3\n",
      " 3 3 3 3 3 3 3 0 3 3 3 0 0 2 3 0 1 3 3 0 3 3 3]\n"
     ]
    }
   ],
   "source": [
    "# Fitting SVC Classification to the Training set with linear kernel\n",
    "# Kernal Function = (xi*xj+1)^d\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svcclassifier2 = SVC(kernel = 'poly', random_state = 0)\n",
    "svcclassifier2.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "x_pred2 = svcclassifier2.predict(X_train)\n",
    "y_pred2 = svcclassifier2.predict(X_test)\n",
    "print(y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 3],\n",
       "       [3, 3]])"
      ]
     },
     "execution_count": 470,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets see the actual and predicted value side by side\n",
    "y_compare2 = np.vstack((y_test,y_pred2)).T\n",
    "#actual value on the left side and predicted value on the right hand side\n",
    "#printing the top 5 values\n",
    "y_compare2[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********FOR POLYNOMIAL KERNAL*********\n",
      "\n",
      " Testing Accuracy of SVM using Polynomial Kernel : 70.0%\n",
      " Training Accuracy of SVM using Polynomial Kernal : 89.83050847457628%\n",
      "1) Confusion Matrix:  \n",
      "[[10  0  0  5]\n",
      " [ 0  4  0  5]\n",
      " [ 5  0  3  1]\n",
      " [ 2  0  0 25]]\n",
      "\n",
      "2) Shape of Confusion Matrix\n",
      "(4, 4)\n",
      "\n",
      "3) Correct predictions:   42\n",
      "\n",
      "4)False predictions:  18\n",
      "\n",
      "5)Precision Score:  0.7596\n",
      "\n",
      "6)Recall Score: 0.7000\n",
      "\n",
      "7)F1 Score: 0.6807\n",
      "\n",
      "8)Accuracy of the SVC Clasification (using Polynomial kernal)is:  70.0%"
     ]
    }
   ],
   "source": [
    "print('*********FOR POLYNOMIAL KERNAL*********')\n",
    "\n",
    "ac2=accuracy_score(y_test, y_pred2)\n",
    "print('\\n Testing Accuracy of SVM using Polynomial Kernel :',ac2*100,end='%')\n",
    "\n",
    "tac2 = accuracy_score(y_train, x_pred2)\n",
    "print('\\n Training Accuracy of SVM using Polynomial Kernal :',tac2*100,end='%')\n",
    "\n",
    "\n",
    "\n",
    "print('\\n1) Confusion Matrix:  ')\n",
    "\n",
    "cm2 = confusion_matrix(y_test, y_pred2)\n",
    "print(cm2)\n",
    "\n",
    "print('\\n2) Shape of Confusion Matrix')\n",
    "a2 = cm2.shape\n",
    "print(a2)\n",
    "\n",
    "\n",
    "corrPred2 = 0\n",
    "falsePred2 = 0\n",
    "\n",
    "for row2 in range(a2[0]):\n",
    "    for c2 in range(a2[1]):\n",
    "        if row2 == c2:\n",
    "            corrPred2 +=cm2[row2,c2]\n",
    "        else:\n",
    "            falsePred2 += cm2[row2,c2]\n",
    "     \n",
    "  \n",
    "print('\\n3) Correct predictions:  ', corrPred2)\n",
    "print('\\n4)False predictions: ', falsePred2)\n",
    "\n",
    "kernelPolyAccuracy = corrPred2/(cm2.sum())\n",
    "\n",
    "print(\"\\n5)Precision Score:  {0:.4f}\".format(precision_score(y_test, y_pred2,average='weighted'))) \n",
    "                                                           \n",
    "print(\"\\n6)Recall Score: {0:.4f}\".format(recall_score(y_test, y_pred2, average='weighted'))) \n",
    "                                                    \n",
    "                                                    \n",
    "print(\"\\n7)F1 Score: {0:.4f}\".format(f1_score(y_test,y_pred2,  average='weighted'))) \n",
    "                                           \n",
    "\n",
    "print ('\\n8)Accuracy of the SVC Clasification (using Polynomial kernal)is: ', kernelPolyAccuracy*100,end='%')        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using rbf kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 1 3 3 2 1 0 0 3 3 0 0 0 0 0 0 3 1 0 2 2 3 3 3 0 2 3 0 3 3 0 0 1 3 1 3\n",
      " 3 3 3 3 3 3 3 0 3 3 3 0 0 2 3 0 1 3 3 0 3 0 0]\n"
     ]
    }
   ],
   "source": [
    "# Fitting SVC Classification to the Training set with linear kernel\n",
    "# The input space can be mapped in infinite dimensional space by RBF kernal\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "\n",
    "svcclassifier3 = SVC(kernel = 'rbf', random_state = 0)\n",
    "svcclassifier3.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "x_pred3 = svcclassifier3.predict(X_train)\n",
    "y_pred3 = svcclassifier3.predict(X_test)\n",
    "print(y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 3],\n",
       "       [3, 3]])"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets see the actual and predicted value side by side\n",
    "y_compare3 = np.vstack((y_test,y_pred3)).T\n",
    "#actual value on the left side and predicted value on the right hand side\n",
    "#printing the top 5 values\n",
    "y_compare3[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********FOR RBF KERNAL*********\n",
      "\n",
      " Testing Accuracy of SVM using RBF Kernel : 81.66666666666667%\n",
      " Training Accuracy of SVM using RBF Kernal : 92.79661016949152%\n",
      "1) Confusion Matrix:  \n",
      "[[14  0  0  1]\n",
      " [ 0  6  0  3]\n",
      " [ 4  0  5  0]\n",
      " [ 2  1  0 24]]\n",
      "\n",
      "2) Shape of Confusion Matrix\n",
      "(4, 4)\n",
      "\n",
      "3) Correct predictions:   49\n",
      "\n",
      "4)False predictions:  11\n",
      "\n",
      "5)Precision Score:  0.8393\n",
      "\n",
      "6)Recall Score: 0.8167\n",
      "\n",
      "7)F1 Score: 0.8124\n",
      "Accuracy of the SVC Clasification (using rbf kernal) is:  81.66666666666667\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('*********FOR RBF KERNAL*********')\n",
    "\n",
    "ac3=accuracy_score(y_test, y_pred3)\n",
    "print('\\n Testing Accuracy of SVM using RBF Kernel :',ac3*100,end='%')\n",
    "\n",
    "tac3 = accuracy_score(y_train, x_pred3)\n",
    "print('\\n Training Accuracy of SVM using RBF Kernal :',tac3*100,end='%')\n",
    "\n",
    "\n",
    "\n",
    "print('\\n1) Confusion Matrix:  ')\n",
    "\n",
    "cm3 = confusion_matrix(y_test, y_pred3)\n",
    "print(cm3)\n",
    "\n",
    "print('\\n2) Shape of Confusion Matrix')\n",
    "a3 = cm3.shape\n",
    "print(a3)\n",
    "\n",
    "\n",
    "corrPred3 = 0\n",
    "falsePred3 = 0\n",
    "\n",
    "for row3 in range(a3[0]):\n",
    "    for c3 in range(a3[1]):\n",
    "        if row3 == c3:\n",
    "            corrPred3 +=cm3[row3,c3]\n",
    "        else:\n",
    "            falsePred3 += cm3[row3,c3]\n",
    "     \n",
    "  \n",
    "print('\\n3) Correct predictions:  ', corrPred3)\n",
    "print('\\n4)False predictions: ', falsePred3)\n",
    "\n",
    "kernelRbfAccuracy = corrPred3/(cm3.sum())\n",
    "\n",
    "print(\"\\n5)Precision Score:  {0:.4f}\".format(precision_score(y_test, y_pred3,average='weighted'))) \n",
    "                                                           \n",
    "print(\"\\n6)Recall Score: {0:.4f}\".format(recall_score(y_test, y_pred3, average='weighted'))) \n",
    "                                                    \n",
    "                                                    \n",
    "print(\"\\n7)F1 Score: {0:.4f}\".format(f1_score(y_test,y_pred3,  average='weighted'))) \n",
    "                                           \n",
    "\n",
    "print ( 'Accuracy of the SVC Clasification (using rbf kernal) is: ', kernelRbfAccuracy*100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using sigmoid kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 1 1 3 3 0 1 0 0 3 3 0 0 0 0 0 0 3 1 0 0 2 3 3 3 0 2 1 3 3 3 0 0 1 3 1 3\n",
      " 3 3 3 3 3 3 3 0 3 3 3 0 0 2 3 0 1 3 3 0 3 3 0]\n"
     ]
    }
   ],
   "source": [
    "# Fitting SVC Classification to the Training set with sigmoid kernel\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svcclassifiers4 = SVC(kernel = 'sigmoid', random_state = 0)\n",
    "svcclassifiers4.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "\n",
    "x_pred4 = svcclassifiers4.predict(X_train)\n",
    "y_pred4 = svcclassifiers4.predict(X_test)\n",
    "print(y_pred4)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 3],\n",
       "       [3, 3]])"
      ]
     },
     "execution_count": 476,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets see the actual and predicted value side by side\n",
    "y_compare4 = np.vstack((y_test,y_pred4)).T\n",
    "#actual value on the left side and predicted value on the right hand side\n",
    "#printing the top 5 values\n",
    "y_compare4[:5,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********FOR SIGMOID KERNAL*********\n",
      "\n",
      " Testing Accuracy of SVM using Sigmoid Kernel : 75.0%\n",
      " Training Accuracy of SVM using Sigmoid Kernal : 92.79661016949152%\n",
      "1) Confusion Matrix:  \n",
      "[[13  0  0  2]\n",
      " [ 0  6  0  3]\n",
      " [ 5  0  3  1]\n",
      " [ 2  2  0 23]]\n",
      "\n",
      "2) Shape of Confusion Matrix\n",
      "(4, 4)\n",
      "\n",
      "3) Correct predictions:   45\n",
      "\n",
      "4)False predictions:  11\n",
      "\n",
      "5)Precision Score:  0.7819\n",
      "\n",
      "6)Recall Score: 0.7500\n",
      "\n",
      "7)F1 Score: 0.7362\n",
      "Accuracy of the SVC Clasification (using Sigmoid kernal) is:  75.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('*********FOR SIGMOID KERNAL*********')\n",
    "\n",
    "ac4=accuracy_score(y_test, y_pred4)\n",
    "print('\\n Testing Accuracy of SVM using Sigmoid Kernel :',ac4*100,end='%')\n",
    "\n",
    "tac4 = accuracy_score(y_train, x_pred3)\n",
    "print('\\n Training Accuracy of SVM using Sigmoid Kernal :',tac4*100,end='%')\n",
    "\n",
    "\n",
    "\n",
    "print('\\n1) Confusion Matrix:  ')\n",
    "\n",
    "cm4 = confusion_matrix(y_test, y_pred4)\n",
    "print(cm4)\n",
    "\n",
    "print('\\n2) Shape of Confusion Matrix')\n",
    "a4 = cm4.shape\n",
    "print(a4)\n",
    "\n",
    "\n",
    "corrPred4 = 0\n",
    "falsePred4 = 0\n",
    "\n",
    "for row4 in range(a4[0]):\n",
    "    for c4 in range(a4[1]):\n",
    "        if row4 == c4:\n",
    "            corrPred4 +=cm4[row4,c4]\n",
    "        else:\n",
    "            falsePred4 += cm3[row4,c4]\n",
    "     \n",
    "  \n",
    "print('\\n3) Correct predictions:  ', corrPred4)\n",
    "print('\\n4)False predictions: ', falsePred4)\n",
    "\n",
    "kernelSfAccuracy = corrPred4/(cm4.sum())\n",
    "\n",
    "print(\"\\n5)Precision Score:  {0:.4f}\".format(precision_score(y_test, y_pred4,average='weighted'))) \n",
    "                                                           \n",
    "print(\"\\n6)Recall Score: {0:.4f}\".format(recall_score(y_test, y_pred4, average='weighted'))) \n",
    "                                                    \n",
    "                                                    \n",
    "print(\"\\n7)F1 Score: {0:.4f}\".format(f1_score(y_test,y_pred4,  average='weighted'))) \n",
    "                                           \n",
    "\n",
    "print ( 'Accuracy of the SVC Clasification (using Sigmoid kernal) is: ', kernelSfAccuracy*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------\n",
      "\t\t\tDecision Tree\n",
      "\n",
      "Confusion matrix for decision tree classifier : \n",
      "[[10  1  0  4]\n",
      " [ 0  7  0  2]\n",
      " [ 2  1  6  0]\n",
      " [ 6  3  1 17]]\n",
      "\n",
      " Testing Accuracy for Decision Tree : 66.66666666666666%\n",
      " Training Accuracy for Decision Tree : 100.0%\n",
      "7)F1 Score: 0.6700\n",
      "\n",
      "\n",
      "Precision for Decision Tree :  0.5555555555555556\n",
      "\n",
      "Recall for Decision Tree :  0.6666666666666666\n",
      "\n",
      "-------------------------------------------------------\n",
      "\n",
      "-------------------------------------------------------\n",
      "\t\t\tLogistic Regression\n",
      "\n",
      "Confusion matrix for Logistic Regression : \n",
      "[[13  1  0  1]\n",
      " [ 0  6  0  3]\n",
      " [ 2  1  5  1]\n",
      " [ 2  1  0 24]]\n",
      "\n",
      "Testing Accuracy for Logistic Regression : 80.0%\n",
      "7)F1 Score: 0.7960\n",
      "\n",
      "Training Accuracy for Logistic Regression : 90.67796610169492%\n",
      "\n",
      "Precision for Logistic Regression :  0.5555555555555556\n",
      "\n",
      "Recall for Logistic Regression :  0.6666666666666666\n",
      "\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "print(\"\\n-------------------------------------------------------\")\n",
    "print(\"\\t\\t\\tDecision Tree\")\n",
    "\n",
    "model_DecisionTree = DecisionTreeClassifier()\n",
    "model_DecisionTree.fit(X_train, y_train)\n",
    "y_predict=model_DecisionTree.predict(X_test)\n",
    "X_predict = model_DecisionTree.predict(X_train)\n",
    "print(\"\\nConfusion matrix for decision tree classifier : \")\n",
    "print(confusion_matrix(y_test,y_predict))\n",
    "\n",
    "a4 = cm4.shape\n",
    "print(a4)\n",
    "\n",
    "\n",
    "corrPred4 = 0\n",
    "falsePred4 = 0\n",
    "\n",
    "for row4 in range(a4[0]):\n",
    "    for c4 in range(a4[1]):\n",
    "        if row4 == c4:\n",
    "            corrPred4 +=cm4[row4,c4]\n",
    "        else:\n",
    "            falsePred4 += cm3[row4,c4]\n",
    "     \n",
    "  \n",
    "print('\\n3) Correct predictions:  ', corrPred4)\n",
    "print('\\n4)False predictions: ', falsePred4)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('\\n Testing Accuracy for Decision Tree :',ac*100,end='%')\n",
    "tac=accuracy_score(y_train, X_predict)\n",
    "print('\\n Training Accuracy for Decision Tree :',tac*100,end='%')\n",
    "pre=precision_recall_fscore_support(y_test, y_predict) \n",
    "#print(pre)\n",
    "print(\"\\n7)F1 Score: {0:.4f}\".format(f1_score(y_test,y_predict,  average='weighted'))) \n",
    "\n",
    "a4 = cm4.shape\n",
    "print(a4)\n",
    "\n",
    "\n",
    "corrPred4 = 0\n",
    "falsePred4 = 0\n",
    "\n",
    "for row4 in range(a4[0]):\n",
    "    for c4 in range(a4[1]):\n",
    "        if row4 == c4:\n",
    "            corrPred4 +=cm4[row4,c4]\n",
    "        else:\n",
    "            falsePred4 += cm3[row4,c4]\n",
    "     \n",
    "  \n",
    "print('\\n3) Correct predictions:  ', corrPred4)\n",
    "print('\\n4)False predictions: ', falsePred4)\n",
    "print(\"\\n\\nPrecision for Decision Tree : \",pre[0][0])\n",
    "#print(pre[0][0]) #precision   (tp/(tp+fp)\n",
    "print(\"\\nRecall for Decision Tree : \",pre[1][0])\n",
    "#print(pre[1][0]) #Recall     (tp/tp+fn)\n",
    "print(\"\\n-------------------------------------------------------\")\n",
    "\n",
    "# Logistic regression\n",
    "print(\"\\n-------------------------------------------------------\")\n",
    "print(\"\\t\\t\\tLogistic Regression\")\n",
    "clf = LogisticRegression(random_state=0, solver='newton-cg', multi_class='multinomial').fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print('\\nConfusion matrix for Logistic Regression : ')\n",
    "print(cm)\n",
    "#score = clf.score(y_test,y_pred)\n",
    "score = clf.score(X_test,y_test)\n",
    "print('\\nTesting Accuracy for Logistic Regression :',score*100,end='%')\n",
    "tscore = clf.score(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "a4 = cm4.shape\n",
    "print(a4)\n",
    "\n",
    "\n",
    "corrPred4 = 0\n",
    "falsePred4 = 0\n",
    "\n",
    "for row4 in range(a4[0]):\n",
    "    for c4 in range(a4[1]):\n",
    "        if row4 == c4:\n",
    "            corrPred4 +=cm4[row4,c4]\n",
    "        else:\n",
    "            falsePred4 += cm3[row4,c4]\n",
    "     \n",
    "  \n",
    "print('\\n3) Correct predictions:  ', corrPred4)\n",
    "print('\\n4)False predictions: ', falsePred4)\n",
    "\n",
    "print(\"\\n7)F1 Score: {0:.4f}\".format(f1_score(y_test,y_pred,  average='weighted'))) \n",
    "print('\\nTraining Accuracy for Logistic Regression :',tscore*100,end='%')\n",
    "pre = precision_recall_fscore_support(y_test, y_predict) \n",
    "#print(pre)\n",
    "print(\"\\n\\nPrecision for Logistic Regression : \",pre[0][0])\n",
    "#print(pre[0][0]) #precision   (tp/(tp+fp)\n",
    "print(\"\\nRecall for Logistic Regression : \",pre[1][0])\n",
    "#print(pre[1][0]) #Recall     (tp/tp+fn)\n",
    "print(\"\\n-------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------------------------------------------------------\n",
      "\t\t\tNaive Bayes\n",
      "\n",
      "Confusion matrix for Naive Bayes classifier : \n",
      "[[11  0  1  3]\n",
      " [ 0  7  0  2]\n",
      " [ 3  0  6  0]\n",
      " [ 3  4  0 20]]\n",
      "\n",
      "Testing Accuracy for Naive Bayes : 73.33333333333333%\n",
      "Training Accuracy for Naive Bayes : 81.77966101694916%(4, 4)\n",
      "\n",
      "3) Correct predictions:   45\n",
      "\n",
      "4)False predictions:  11\n",
      "\n",
      "7)F1 Score: 0.7355\n",
      "\n",
      "Precision for Naive Bayes classifier :  0.6470588235294118\n",
      "\n",
      "Recall for Naive Bayes classifier :  0.7333333333333333\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes\n",
    "#print(\"\\n\\nNaive Bayes\")\n",
    "s=StandardScaler()\n",
    "#z-score normalization values in 0,1 format\n",
    "x_scale = s.fit_transform(X)\n",
    "\n",
    "classifier = GaussianNB()\n",
    "classifier.fit(X_train,y_train)\n",
    "#fitting data and trying to predict test data\n",
    "\n",
    "x_predict = classifier.predict(X_train)\n",
    "y_predict = classifier.predict(X_test)\n",
    "cm = confusion_matrix(y_test,y_predict)\n",
    "print(\"\\n------------------------------------------------------------\")\n",
    "print(\"\\t\\t\\tNaive Bayes\")\n",
    "print(\"\\nConfusion matrix for Naive Bayes classifier : \")\n",
    "print(cm)\n",
    "ac = accuracy_score(y_test,y_predict)\n",
    "print('\\nTesting Accuracy for Naive Bayes :',ac*100,end='%')\n",
    "tac= accuracy_score(y_train, x_predict)\n",
    "print('\\nTraining Accuracy for Naive Bayes :',tac*100,end='%')\n",
    "\n",
    "\n",
    "\n",
    "a4 = cm4.shape\n",
    "print(a4)\n",
    "\n",
    "\n",
    "corrPred4 = 0\n",
    "falsePred4 = 0\n",
    "\n",
    "for row4 in range(a4[0]):\n",
    "    for c4 in range(a4[1]):\n",
    "        if row4 == c4:\n",
    "            corrPred4 +=cm4[row4,c4]\n",
    "        else:\n",
    "            falsePred4 += cm3[row4,c4]\n",
    "     \n",
    "  \n",
    "print('\\n3) Correct predictions:  ', corrPred4)\n",
    "print('\\n4)False predictions: ', falsePred4)\n",
    "pre=precision_recall_fscore_support(y_test, y_predict) \n",
    "print(\"\\n7)F1 Score: {0:.4f}\".format(f1_score(y_test,y_predict,  average='weighted'))) \n",
    "#print(pre)\n",
    "print(\"\\nPrecision for Naive Bayes classifier : \",pre[0][0])\n",
    "#print(pre[0][0]) #precision   (tp/(tp+fp)\n",
    "print(\"\\nRecall for Naive Bayes classifier : \",pre[1][0])\n",
    "#print(pre[1][0]) #Recall     (tp/tp+fn)\n",
    "print(\"\\n------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
